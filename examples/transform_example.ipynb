{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede7c638",
   "metadata": {},
   "source": [
    "# Transform example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12276e23",
   "metadata": {},
   "source": [
    "In this example we will use a consistency regularisation method with some transformations to achieve semi supervised learning. We are using MNIST with a simple CNN for classification, trained using the FixMatch algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "578fe050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wslearn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322afd7b",
   "metadata": {},
   "source": [
    "Importing the data from torchvision and normalising the pixel values to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe53d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "mnist_tr = MNIST(root=\"~/.wslearn/datasets\", train=True, download=True)\n",
    "mnist_ts = MNIST(root=\"~/.wslearn/datasets\", train=False, download=True)\n",
    "\n",
    "X_tr, y_tr = mnist_tr.data.float()/255, mnist_tr.targets\n",
    "X_ts, y_ts = mnist_ts.data.float()/255, mnist_ts.targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a4792",
   "metadata": {},
   "source": [
    "Let's define some transformations. FixMatch expects a weak and strong transformation to be defined. Since the data is currently a torch tensor, we convert it to PIL image then apply any transforms, before converting it back to a torch tensor. The weak transform is just a random horizontal flip, the strong transform is a flip along with a random augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e9aadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "strong_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd10919a",
   "metadata": {},
   "source": [
    "We are using a CNN so we will add a channels dimension (only one channel in this case for graycsale images). Then we can split the data into the labelled and unlabelled parts, and use TransformDataset from wslearn to obtain samples. TransformDataset can handle the weak and strong transformations for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bbdc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wslearn.utils.data import TransformDataset\n",
    "from wslearn.utils.data import split_lb_ulb_balanced\n",
    "\n",
    "X_tr = X_tr.unsqueeze(1)\n",
    "X_ts = X_ts.unsqueeze(1)\n",
    "num_labels_per_class = 4\n",
    "\n",
    "\n",
    "X_tr_lb, y_tr_lb, X_tr_ulb, y_tr_ulb = split_lb_ulb_balanced(X_tr, y_tr, num_labels_per_class)\n",
    "\n",
    "\n",
    "lbl_dataset = TransformDataset(X_tr_lb, y_tr_lb, weak_transform=weak_transform, strong_transform=strong_transform)\n",
    "ulbl_dataset = TransformDataset(X_tr_ulb, y_tr_ulb, weak_transform=weak_transform, strong_transform=strong_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3877cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wslearn.algorithms import FixMatch\n",
    "\n",
    "algorithm = FixMatch(lambda_u=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39417cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wslearn.utils.data import CyclicLoader\n",
    "\n",
    "lbl_batch_size = 20\n",
    "ulbl_batch_size = 60\n",
    "train_loader = CyclicLoader(lbl_dataset, ulbl_dataset, lbl_batch_size=lbl_batch_size, ulbl_batch_size=ulbl_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbdec952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_device(d, device):\n",
    "    return {k: v.to(device) if torch.is_tensor(v) else v for k, v in d.items()}\n",
    "\n",
    "def train(model, train_loader, algorithm,  optimizer, num_iters=128,\n",
    "          num_log_iters = 8, device=\"cpu\"):\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    training_bar = tqdm(train_loader, total=num_iters, desc=\"Training\",\n",
    "                        leave=True)\n",
    "\n",
    "    for i, (lbl_batch, ulbl_batch) in enumerate(training_bar):\n",
    "\n",
    "        lbl_batch = dict_to_device(lbl_batch, device)\n",
    "        ulbl_batch = dict_to_device(ulbl_batch, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = algorithm.forward(model, lbl_batch, ulbl_batch)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % num_log_iters == 0:\n",
    "            training_bar.set_postfix(loss = round(loss.item(), 4))\n",
    "\n",
    "        if i > num_iters:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "773ae93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 max pooling\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # 28 -> 14 -> 7 after 2 poolings\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> [batch, 16, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> [batch, 32, 7, 7]\n",
    "        x = x.view(x.size(0), -1)             # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ca6c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed725530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 1001it [00:37, 26.69it/s, loss=0.0387]                          \n"
     ]
    }
   ],
   "source": [
    "train(model=model, train_loader=train_loader, algorithm=algorithm,\n",
    "      optimizer=optimizer, device=device, num_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eea26318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wslearn.utils.data import BasicDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "X_ts, y_ts = X_ts.float(), y_ts.float()\n",
    "\n",
    "test_dataset = BasicDataset(X_ts, y_ts)\n",
    "test_loader = DataLoader(test_dataset, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad3e9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix\n",
    ")\n",
    "\n",
    "def evaluate(model, eval_loader, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total_num = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            X = batch[\"X\"].to(device)\n",
    "            y = batch[\"y\"].to(device)\n",
    "            num_batch = y.shape[0]\n",
    "            total_num += num_batch\n",
    "            logits = model(X)\n",
    "            y_true.extend(y.cpu().tolist())\n",
    "            y_pred.extend(torch.max(logits, dim=-1)[1].cpu().tolist())\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        print(\"accuracy: \", acc)\n",
    "        cf_mat = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "\n",
    "        with np.printoptions(suppress=True, precision=3):\n",
    "            print('confusion matrix:\\n' + np.array_str(cf_mat))\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc9db37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7751\n",
      "confusion matrix:\n",
      "[[0.918 0.03  0.    0.    0.012 0.    0.015 0.005 0.009 0.01 ]\n",
      " [0.    0.989 0.004 0.    0.    0.    0.007 0.    0.    0.   ]\n",
      " [0.002 0.001 0.704 0.002 0.05  0.009 0.125 0.013 0.084 0.01 ]\n",
      " [0.001 0.003 0.04  0.125 0.002 0.484 0.114 0.007 0.177 0.048]\n",
      " [0.    0.007 0.    0.    0.961 0.    0.    0.    0.    0.032]\n",
      " [0.004 0.003 0.026 0.016 0.007 0.598 0.058 0.176 0.067 0.045]\n",
      " [0.005 0.03  0.005 0.    0.056 0.001 0.896 0.    0.004 0.002]\n",
      " [0.    0.018 0.007 0.    0.012 0.    0.    0.847 0.014 0.102]\n",
      " [0.002 0.084 0.001 0.033 0.02  0.017 0.034 0.016 0.762 0.031]\n",
      " [0.006 0.023 0.004 0.002 0.021 0.004 0.003 0.006 0.013 0.919]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f19ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wslearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
