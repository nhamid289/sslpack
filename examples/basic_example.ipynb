{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca53afb",
   "metadata": {},
   "source": [
    "# Iris basic example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a9ba5",
   "metadata": {},
   "source": [
    "In this example, we will use Pseudo labelling to classify the iris dataset with a simple MLP using `sslpack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72928f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sslpack\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75dbdf3",
   "metadata": {},
   "source": [
    "Iris is not provided in `sslpack`, so we will first use sci-kit learn to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4060c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894d780",
   "metadata": {},
   "source": [
    "We would like to generate a train-test split, but also partition the training data into a labelled and unlabelled part. We can use a `sslpack` function to achieve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b7f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1625967/1286055813.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  X_tr_lb, y_tr_lb  = torch.tensor(X_tr_lb), torch.tensor(y_tr_lb)\n"
     ]
    }
   ],
   "source": [
    "from sslpack.utils.data import split_lb_ulb_balanced\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "num_labels_per_class = 2\n",
    "X_tr_lb, y_tr_lb, X_tr_ulb, y_tr_ulb = split_lb_ulb_balanced(X_tr, y_tr, num_labels_per_class)\n",
    "\n",
    "X_tr_lb, y_tr_lb  = torch.tensor(X_tr_lb), torch.tensor(y_tr_lb)\n",
    "X_tr_ulb, y_tr_ulb = torch.tensor(X_tr_ulb), torch.tensor(y_tr_ulb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe30d2",
   "metadata": {},
   "source": [
    "`sslpack` expects datasets to return dictionaries to support the various transformations that are required by consistency regularisation methods. For this example, we have no transformations, but we need the correct dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sslpack.utils.data import BasicDataset\n",
    "lbl_dataset = BasicDataset(X_tr_lb, y_tr_lb)\n",
    "ulbl_dataset = BasicDataset(X_tr_ulb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b6b6c",
   "metadata": {},
   "source": [
    "Now we can import the implementation of Pseudo label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sslpack.algorithms import PseudoLabel\n",
    "algorithm= PseudoLabel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300a012",
   "metadata": {},
   "source": [
    "Unlike conventional supervised learning, our dataloaders need to handle two streams - a labelled and unlabelled part. Therefore, `sslpack` provides such dataloader, such as the CyclicLoader. We just need to specify the batch size of the labelled and unlabelled parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sslpack.utils.data import CyclicLoader\n",
    "\n",
    "lbl_batch_size = 6\n",
    "ulbl_batch_size = 12\n",
    "train_loader = CyclicLoader(lbl_dataset, ulbl_dataset, lbl_batch_size=lbl_batch_size, ulbl_batch_size=ulbl_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee74a0",
   "metadata": {},
   "source": [
    "Now we can write a training function. `sslpack` is designed to be similar to convential SSL torch code, and as such the training loop is hopefully familiar. However, we replace the main training logic by the forward pass of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063514ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_device(d, device):\n",
    "    return {k: v.to(device) if torch.is_tensor(v) else v for k, v in d.items()}\n",
    "\n",
    "def train(model, train_loader, algorithm,  optimizer, num_iters=128,\n",
    "          num_log_iters = 8, device=\"cpu\"):\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    training_bar = tqdm(train_loader, total=num_iters, desc=\"Training\",\n",
    "                        leave=True)\n",
    "\n",
    "    for i, (lbl_batch, ulbl_batch) in enumerate(training_bar):\n",
    "\n",
    "        lbl_batch = dict_to_device(lbl_batch, device)\n",
    "        ulbl_batch = dict_to_device(ulbl_batch, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = algorithm.forward(model, lbl_batch, ulbl_batch)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % num_log_iters == 0:\n",
    "            training_bar.set_postfix(loss = round(loss.item(), 4))\n",
    "\n",
    "        if i > num_iters:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70094a87",
   "metadata": {},
   "source": [
    "All the remains is to specify a model and optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2785b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(4, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 3)\n",
    ")\n",
    "\n",
    "model.double()\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6a066",
   "metadata": {},
   "source": [
    "We can now train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7730ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 101it [00:00, 127.66it/s, loss=0.0037]                        \n"
     ]
    }
   ],
   "source": [
    "train(model=model, train_loader=train_loader, algorithm=algorithm,\n",
    "      optimizer=optimizer, device=device, num_iters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e59eb2",
   "metadata": {},
   "source": [
    "Now testing on the withheld test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f54b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X).argmax(dim=1)\n",
    "        acc = (predictions == y).float().mean()\n",
    "        return float(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deba0f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333373069763"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, torch.tensor(X_ts).to(device), torch.tensor(y_ts).to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wslearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
